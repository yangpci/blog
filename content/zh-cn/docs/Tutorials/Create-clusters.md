---
title: "创建集群"
date: 2022-11-29
weight: 2
description: >
  KubeClipper 支持通过向导式页面创建 kubernetes 集群，并安装 CNI、CSI 等所需插件。
---

## 创建集群准备工作

1. 您需要准备充足的可用节点，如需添加节点，参见“[添加节点](/docs/tutorials/node-management/#添加节点)”教程。
2. 准备好需要部署的 kubernetes、CRI、calico、CSI 和其他插件的镜像或二进制文件，kubeclipper 提供了推荐的版本，您可以根据平台所处网络环境，选择在线 / 离线后，直接在页面上选取使用。您也可以将部署所需的镜像上传至自己的镜像仓库，并在部署时指定。更多安装配置，参考“[集群配置](#集群配置)”章节。

## 创建单节点实验集群

1. 点击“集群管理”>“集群”，进入集群列表页面，点击左上角“创建集群”按钮。

2. 进入创建集群向导页面的“节点配置”页面。填写“集群名称”，如 “test”，不需选择“集群模版”。选择一个可用节点，添加为控制节点，并在污点管理列表中，将 master 节点的污点移除。点击“下一步”按钮。

![](/images/docs-tutorials/aio.png)

3. 进入创建集群向导页面的“集群配置”页面。选择“离线安装”，“镜像仓库”不需填写，其他配置都可使用默认配置，点击“快速创建”按钮，跳转配置确认页面，点击“确认”按钮。

4. 单节点的实验集群创建完成，您可以在集群详情页查看集群详情，也可以点击“查看日志”按钮，查看集群创建过程中的实时日志。

## 使用镜像仓库创建集群

如果创建的集群中包含较大的镜像，推荐您将所有镜像上传到特定的镜像仓库，创建集群会更快速更顺畅。

1. 添加镜像仓库。点击“集群管理”>“镜像仓库”，进入镜像仓库列表页面，点击左上角“添加”按钮。在添加镜像仓库的弹窗中输入镜像仓库名称和存放有镜像的仓库地址，点击“确定”按钮。
2. 创建集群。点击“集群管理”>“集群”，进入集群列表页面，点击左上角“创建集群”按钮。按需配置集群节点，在“集群配置”页面的“镜像仓库”中，选择第一步添加的镜像仓库，根据需要完成集群其他配置后创建集群。

## 使用集群模版创建集群

您可以使用集群模版，简化集群创建流程。

1. 添加模版。保存模版有两种方式，您可以在“集群管理”>“模版管理”页面，添加集群模版，以备创建集群时使用。也可以点击集群操作中的“更多”>“保存为模版”，将已存在的集群配置保存为模版，以便创建出和该集群同等配置的 kubernetes 集群。
2. 创建集群。点击“集群管理”>“集群”，进入集群列表页面，点击左上角“创建集群”按钮，进入创建集群页面，填写“集群名称”，如 “demo”，选择第一步中保存的集群模版，添加所需节点，点击右下角“快速创建”按钮，跳转至“配置确认”页面，核对模版信息无误后，点击“确认”按钮，创建集群。

## 集群配置指南

### 节点配置

在节点配置页面，您可以对节点进行以下配置：

- 区域：集群所属区域，添加节点时可为节点指定物理的或逻辑的区域，使用该区域下节点创建的 kubernetes 集群也属于该区域，不支持使用跨区域的多个节点创建集群。
- 控制节点：为集群指定奇数个的控制节点，生产环境一般使用3个控制节点以实现高可用。
- 工作节点：根据业务规模，为新集群添加工作节点。
- 污点管理：您可以为已添加的节点配置污点，kubeclipper 会自动为控制节点添加不允许调度（noschedule）的污点，您也可以根据需要进行更改。
- 节点标签：您可以根据需要为已添加的集群节点配置标签。

您可以按业务需要配置所需节点。如果需要创建非高可用的实验集群，也可以仅添加一个控制节点，并将控制节点自动添加的污点移除，详细操作参见“[创建单节点实验集群](#创建单节点实验集群)”。

### 集群配置

在集群配置页面，您可以对集群进行以下配置：

- 安装方式和镜像仓库：

|                      | 镜像仓库为空                                                                                                                                                                                                                                                | 指定镜像仓库                                                 |
| -------------------- |-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------| ------------------------------------------------------------ |
| **在线（公网环境）** | 配置包来源：从 kubeclipper.io  下载。<br />镜像拉取方式：镜像默认从官方镜像仓库拉取，如 kubernetes 镜像从 k8s.gcr.io 拉取、calico 从 docker.io 拉取。如果您设置了国内镜像代理，镜像会从您指定的 “KC_IMAGE_REPO_MIRROR” 代理仓库拉取。                                                                                       | 配置包来源：从  kubeclipper.io  下载。<br />镜像拉取方式：从填写的镜像仓库拉取，组件将默认继承该仓库地址，请确保该仓库存在相关组件镜像；组件也会提供独立的镜像仓库参数，设置后组件镜像从该地址拉取。 |
| **离线（内网环境）** | 配置包来源：从本地  kubeclipper 集群 server 节点下载，您可以使用 kcctl resource list 命令查看本地可用配置包，或使用 kcctl  resource push 命令上传所需配置包。<br />镜像拉取方式：从本地 kubeclipper  集群 server 节点下载，下载后由 CRI 进行镜像导入。您可以使用 kcctl resource list 命令查看本地可用镜像包，或使用 kcctl  resource push 命令上传所需镜像包。 | 配置包来源：从本地下载，您可以使用  kcctl resource list 命令查看本地可用配置包，或使用 kcctl resource push  命令上传所需配置包。<br />镜像拉取方式：从填写的镜像仓库拉取，组件将默认继承该仓库地址，请确保该仓库存在相关组件镜像；组件也会提供独立的镜像仓库参数，设置后组件镜像从该地址拉取。kubeclipper  提供 Docker Registry 方案，并使用 kcctl registry 命令行进行管理，您也可以使用其他自有镜像仓库。 |

- kubernetes 版本：指定集群 kubernetes 版本。当您选择离线安装的时候，可以从当前环境中配置包的 kubernetes 版本中选择；当您选择在线安装的时候，可以从 kubeclipper 官方推荐的版本中选择。

- ETCD 数据目录：可指定 ETCD 数据目录，默认为/var/lib/etcd。

- kubelet 数据目录：可指定 kubelet 数据目录，默认为 /var/lib/kubelet。

- CertSANs：kubernetes 集群 ca 证书签名的 ip 或者域名，可填写多个。

- 容器运行时：根据指定 kubernetes 版本，kubernetes 版本在 v1.20.0 之前，容器运行时默认 docker，之后默认 containerd；v1.24.0 之后不支持 docker。

- 容器运行时版本：指定 containerd / docker 版本。与 kubernetes 相同，当您选择离线安装的时候，可以从当前环境中配置包的版本中选择；当您选择在线安装的时候，可以从 kubeclipper 官方推荐的版本中选择。

- Containerd 数据目录：可填写 config.toml 配置中的 root dir，默认为/var/lib/containerd。

- Docker 数据目录：可填写 daemon.json 配置中的 root dir，默认为/var/lib/docker。

- Containerd 镜像仓库：存放 containerd 镜像的仓库地址，config.toml 配置中的 registry.mirrors，可填写多个。

- Docker 镜像仓库：存放 docker 镜像的仓库地址，daemon.json 配置中的 insecure registry,可填写多个。

- DNS 域名：kubernetes 集群的域名，默认为 cluster.local。

- Worker 负载 IP：用于 worker 节点到多 master 的负载均衡，单一 master 不需要设置。

- 外部访问 IP：可以填写一个浮动 IP 给用户访问，可为空。

- 备份空间：集群备份文件存储位置。

### CNI 配置

当前版本仅支持 Calico 作为集群 CNI。

Calico 将用户设置的 pod cidr 分为若干个 block (网段)，根据业务需求动态的分配给需要的节点，并在节点中通过 bgp peer 维护集群节点的路由表。

例如：容器的地址池：172.25.0.0/16，动态分配的网段池: 172.25.0.0 - 172.25.255.192 (172.25.0.0/26 即 10 个比特位)，动态分配的网段数: 1023，每个网段的 pod 数量为: 61 (193-254)，总 pod 数量为1023 * 61 = 62403，相对最大节点数(按照200业务 pod 为基准值)：312。

目前不建议大于50个节点的集群，大于50个节点的集群建议手动配置 route reflection，用来优化集群中的节点的路由表维护的稳定性。

使用 Calico 作为集群 CNI，您需要进行以下配置：

- Calico 模式：支持5种网络模式：
  - Overlay-IPIP-All: 使用 IP-in-IP 技术打通不同节点的 pod 的网络,通常这样的方式使用在底层平台是 iaas 的环境之中,当然如果你底层网路环境直接是物理设备的也完全可以使用只不过效率和灵活度都会大打折扣,需要注意的是你需要确认底层网络环境(underlay)是支持 IPIP 协议的.(使用 overlay 的网络方式对网络性能造成一定的影响)。
  - Overlay-Vxlan-All: 使用 IP-in-IP 技术打通不同节点的 pod 的网络,通常这样的方式使用在底层平台是 iaas 的环境之中,当然如果你底层网路环境直接是物理设备的也完全可以使用只不过效率和灵活度都会大打折扣,他理论上可以在任何的网络环境上运行,通常在底层环境不支持 IPIP 协议的时候我们会使用他.(使用 overlay 的网络方式对网络性能造成一定的影响)。
  - BGP: 使用 IP-in-IP 技术打通不同节点的 pod 的网络,通常这样的方式使用在裸机的环境上,当然底 Iaas 平台支持 BGP 的话也是可以使用的,这种模式下 pod 的 ip 通信是通过 集群中的各个节点中互相交换路由表来完成 pod 之间的通信的,如果你需要手动打通多个集群之间的 pod 网络需要注意你分配的地址断不应该有冲突。
  - Overaly-IPIP-Cross-Subnet: 使用 IP-in-IP 技术打通不同节点的 pod 的网络,通常这样的方式使用在底层平台是 iaas 的环境之中,需要注意的是你需要确认底层网络环境(underlay)是支持 IPIP 协议的.和 Overlay-IPIP-All 的不同之处在于,如果 2 个不同节点但在同一个网段中的上 pod 互相通信时是通过路由表,这样可以提高在不同节点但在同一个网段中的上 pod 互相通信时的效率。
  - Overaly-Vxlan-Cross-Subnet: 和 Overaly-IPIP-Cross-Subnet 逻辑相似不再做重复的解释。

- Calico 版本：指定 calico 版本。与 kubernetes 相同，当您选择离线安装的时候，可以从当前环境中配置包的版本中选择；当您选择在线安装的时候，可以从 kubeclipper 官方推荐的版本中选择。

- IP版本：可指定 IP 版本为 IPV4 或 IPV4 IPV6 双栈。

- 服务子网：填写 service 子网 CIDR，v4 默认为：10.96.0.0/16，v6 默认为 fd03::/112，注意 Service 网络不得与任何主机网络重叠。

- Pod CIDR：填写 Pod 子网 CIDR，v4 默认：172.25.0.0/24，v6 默认为 fd05::/120，注意 Pod 网络不得与任何主机网络重叠。

- pod网路的底层： 
  - first-found（默认）：程序会根据 ipfamily (v4 或 v6)遍历所有的有效的 ip 地址（local,loop back，docker bridge等会被自动排除）通常如果是多网卡时会排除默认网关以外的网卡的 ip 作为节点之间的路由地址。
  - can-reach：通过检查域名或者 ip 的可达性来设置节点之间的路由地址。
  - interface：根据正则表达式获取所有满足的网卡设备名称并返回第一个满足表达式网卡的地址作为节点之间的路由地址。

- MTU：为 Calico 环境配置最大传输单元(MTU)，建议不大于1440，默认为1440，详情见 <https://docs.projectcalico.org/networking/mtu>。

###  存储配置

Kubeclipper当前版本内置了 NFS 作为集群外接存储。

对接 NFS 类型的外接存储，您需要设置以下内容：

| 字段         | 作用说明                                       | 填写说明/可选项                                       |
| ------------ | ---------------------------------------------- | ----------------------------------------------------- |
| **服务地址** | ServerAddr，NFS的服务地址                      | 必填                                                  |
| **共享路径** | SharedPath，NFS的服务挂载路径                  | 必填                                                  |
| **存储类**   | StorageClassName，存储类的名称                 | 默认为 nfs-sc，可自定义名称，不可与集群其他存储类重复 |
| **回收策略** | ReclaimPolicy，VPC回收策略                     | 删除 Delete / 保留 Retain                             |
| **挂载选项** | MountOptions，NFS 的 options 参数，如nfsvers=3 | 选填，可填写多个                                      |
| **副本数**   | Replicas，NFS provisioner副本数                | 默认为1                                               |

 设置完外接存储后，下方卡片会显示您已经开启的存储，您可以选择一个存储类作为默认存储，对于未指定特定StorageClass 的 PVC ，会直接使用默认的存储类。

### 配置确认

您可以在配置确认页面浏览集群的配置信息，确认无误后，点击“确认“按钮。也可以点击卡片右侧的“编辑”按钮，跳回到相应步骤修改集群信息。

安装集群可能需要较长时间，您可以在集群详情页面查看操作日志，跟踪集群安装状态。

### 设置国内镜像代理（可选）

> Q: 设置国内镜像代理有什么作用？
>
> A: 设置了国内镜像代理，使用在线安装功能时，会从指定代理拉取 kubernetes 相关镜像，避免在国内无法访问 gcr 而导致集群安装失败问题。

以下设置方法需在执行 `kcctl deploy` 部署命令的机器上完成，任选其一即可。

**方式一：**设置 KC_IMAGE_REPO_MIRROR 环境变量（推荐）

```bash
# 设置环境变量，推荐使用阿里云镜像代理，您也可以自行设定
export KC_IMAGE_REPO_MIRROR="registry.aliyuncs.com/google_containers"
```

**方式二：**设置 /etc/kc/kc.env 环境变量文件

```bash
# 创建 kc 目录
mkdir -pv /etc/kc

# 创建 kc.env 文件并传入环境变量信息
cat <<EOF > /etc/kc/kc.env
KC_IMAGE_REPO_MIRROR="registry.aliyuncs.com/google_containers"
EOF
```

